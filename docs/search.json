[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "mini_project2.html",
    "href": "mini_project2.html",
    "title": "Mini Project 2:Data Scraping",
    "section": "",
    "text": "# check that scraping is allowed (Step 0)\nrobotstxt::paths_allowed(\"https://fbref.com/en/comps/1/schedule/World-Cup-Scores-and-Fixtures\")\n\n\n fbref.com                      \n\n\n[1] TRUE\n\n# Step 1: read_html()\nscores &lt;- read_html(\"https://fbref.com/en/comps/1/schedule/World-Cup-Scores-and-Fixtures\")\n\n# step 2: html_nodes()\ntables &lt;- \n  html_nodes(scores, css = \"table\") \ntables\n\n{xml_nodeset (3)}\n[1] &lt;table class=\"stats_table sortable min_width\" id=\"sched_all\" data-cols-to ...\n[2] &lt;table class=\"stats_table sortable min_width\" id=\"sched_2022_1_1\" data-co ...\n[3] &lt;table class=\"stats_table sortable min_width\" id=\"sched_2022_1_2\" data-co ...\n\n# 3: html_table()\nhtml_table(tables, header = TRUE, fill = TRUE)\n\n[[1]]\n# A tibble: 67 × 15\n   Round     Wk Day   Date  Time  Home     xG Score    xG Away  Attendance Venue\n   &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;\n 1 Group…     1 Sun   2022… 19:00 Qata…   0.3 0–2     1.2 ec E… 67,372     Al B…\n 2 Group…     1 Mon   2022… 16:00 Engl…   2.1 6–2     1.4 ir I… 45,334     Khal…\n 3 Group…     1 Mon   2022… 19:00 Sene…   0.9 0–2     0.7 nl N… 41,721     Al T…\n 4 Group…     1 Mon   2022… 22:00 Unit…   0.8 1–1     1.5 wls … 43,418     Ahme…\n 5 Group…     1 Tue   2022… 13:00 Arge…   2.2 1–2     0.1 sa S… 88,012     Lusa…\n 6 Group…     1 Tue   2022… 16:00 Denm…   1.4 0–0     0.9 tn T… 42,925     Educ…\n 7 Group…     1 Tue   2022… 19:00 Mexi…   0.7 0–0     0.9 pl P… 39,369     Stad…\n 8 Group…     1 Tue   2022… 22:00 Fran…   4   4–1     0.5 au A… 40,875     Al J…\n 9 Group…     1 Wed   2022… 13:00 Moro…   0.4 0–0     0.5 hr C… 59,407     Al B…\n10 Group…     1 Wed   2022… 16:00 Germ…   3.1 1–2     1.5 jp J… 42,608     Khal…\n# ℹ 57 more rows\n# ℹ 3 more variables: Referee &lt;chr&gt;, `Match Report` &lt;chr&gt;, Notes &lt;chr&gt;\n\n[[2]]\n# A tibble: 50 × 14\n      Wk Day   Date       Time  Home       xG Score    xG Away  Attendance Venue\n   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;\n 1     1 Sun   2022-11-20 19:00 Qatar …   0.3 0–2     1.2 ec E… 67,372     Al B…\n 2     1 Mon   2022-11-21 16:00 Englan…   2.1 6–2     1.4 ir I… 45,334     Khal…\n 3     1 Mon   2022-11-21 19:00 Senega…   0.9 0–2     0.7 nl N… 41,721     Al T…\n 4     1 Mon   2022-11-21 22:00 United…   0.8 1–1     1.5 wls … 43,418     Ahme…\n 5     1 Tue   2022-11-22 13:00 Argent…   2.2 1–2     0.1 sa S… 88,012     Lusa…\n 6     1 Tue   2022-11-22 16:00 Denmar…   1.4 0–0     0.9 tn T… 42,925     Educ…\n 7     1 Tue   2022-11-22 19:00 Mexico…   0.7 0–0     0.9 pl P… 39,369     Stad…\n 8     1 Tue   2022-11-22 22:00 France…   4   4–1     0.5 au A… 40,875     Al J…\n 9     1 Wed   2022-11-23 13:00 Morocc…   0.4 0–0     0.5 hr C… 59,407     Al B…\n10     1 Wed   2022-11-23 16:00 German…   3.1 1–2     1.5 jp J… 42,608     Khal…\n# ℹ 40 more rows\n# ℹ 3 more variables: Referee &lt;chr&gt;, `Match Report` &lt;chr&gt;, Notes &lt;lgl&gt;\n\n[[3]]\n# A tibble: 20 × 14\n   Round        Day   Date  Time  Home     xG Score    xG Away  Attendance Venue\n   &lt;chr&gt;        &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;\n 1 \"Round of 1… \"Sat\" \"202… \"18:… \"Net…   1.7 \"3–1\"   1.5 \"us … \"44,846\"   \"Kha…\n 2 \"Round of 1… \"Sat\" \"202… \"22:… \"Arg…   1.6 \"2–1\"   0.6 \"au … \"45,032\"   \"Ahm…\n 3 \"Round of 1… \"Sun\" \"202… \"18:… \"Fra…   1.4 \"3–1\"   1.7 \"pl … \"40,989\"   \"Al …\n 4 \"Round of 1… \"Sun\" \"202… \"22:… \"Eng…   0.9 \"3–0\"   0.7 \"sn … \"65,985\"   \"Al …\n 5 \"Round of 1… \"Mon\" \"202… \"18:… \"Jap…   1.2 \"(1)…   1.4 \"hr … \"42,523\"   \"Al …\n 6 \"Round of 1… \"Mon\" \"202… \"22:… \"Bra…   3.6 \"4–1\"   0.5 \"kr … \"43,847\"   \"Sta…\n 7 \"Round of 1… \"Tue\" \"202… \"18:… \"Mor…   0.7 \"(3)…   1   \"es … \"44,667\"   \"Edu…\n 8 \"Round of 1… \"Tue\" \"202… \"22:… \"Por…   2.3 \"6–1\"   1.1 \"ch … \"83,720\"   \"Lus…\n 9 \"\"           \"\"    \"\"    \"\"    \"\"     NA   \"\"     NA   \"\"    \"\"         \"\"   \n10 \"Quarter-fi… \"Fri\" \"202… \"18:… \"Cro…   0.6 \"(4)…   2.5 \"br … \"43,893\"   \"Edu…\n11 \"Quarter-fi… \"Fri\" \"202… \"22:… \"Net…   0.6 \"(3)…   1.9 \"ar … \"88,235\"   \"Lus…\n12 \"Quarter-fi… \"Sat\" \"202… \"18:… \"Mor…   1.4 \"1–0\"   0.9 \"pt … \"44,198\"   \"Al …\n13 \"Quarter-fi… \"Sat\" \"202… \"22:… \"Eng…   2.4 \"1–2\"   0.9 \"fr … \"68,895\"   \"Al …\n14 \"\"           \"\"    \"\"    \"\"    \"\"     NA   \"\"     NA   \"\"    \"\"         \"\"   \n15 \"Semi-final… \"Tue\" \"202… \"22:… \"Arg…   2.3 \"3–0\"   0.5 \"hr … \"88,966\"   \"Lus…\n16 \"Semi-final… \"Wed\" \"202… \"22:… \"Fra…   2   \"2–0\"   0.9 \"ma … \"68,294\"   \"Al …\n17 \"\"           \"\"    \"\"    \"\"    \"\"     NA   \"\"     NA   \"\"    \"\"         \"\"   \n18 \"Third-plac… \"Sat\" \"202… \"18:… \"Cro…   0.7 \"2–1\"   1.2 \"ma … \"44,137\"   \"Kha…\n19 \"\"           \"\"    \"\"    \"\"    \"\"     NA   \"\"     NA   \"\"    \"\"         \"\"   \n20 \"Final\"      \"Sun\" \"202… \"18:… \"Arg…   3.2 \"(4)…   2.2 \"fr … \"88,966\"   \"Lus…\n# ℹ 3 more variables: Referee &lt;chr&gt;, `Match Report` &lt;chr&gt;, Notes &lt;chr&gt;\n\nscores_data1 &lt;- html_table(tables, header = TRUE, fill = TRUE)[[1]]  \nscores_data1\n\n# A tibble: 67 × 15\n   Round     Wk Day   Date  Time  Home     xG Score    xG Away  Attendance Venue\n   &lt;chr&gt;  &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;\n 1 Group…     1 Sun   2022… 19:00 Qata…   0.3 0–2     1.2 ec E… 67,372     Al B…\n 2 Group…     1 Mon   2022… 16:00 Engl…   2.1 6–2     1.4 ir I… 45,334     Khal…\n 3 Group…     1 Mon   2022… 19:00 Sene…   0.9 0–2     0.7 nl N… 41,721     Al T…\n 4 Group…     1 Mon   2022… 22:00 Unit…   0.8 1–1     1.5 wls … 43,418     Ahme…\n 5 Group…     1 Tue   2022… 13:00 Arge…   2.2 1–2     0.1 sa S… 88,012     Lusa…\n 6 Group…     1 Tue   2022… 16:00 Denm…   1.4 0–0     0.9 tn T… 42,925     Educ…\n 7 Group…     1 Tue   2022… 19:00 Mexi…   0.7 0–0     0.9 pl P… 39,369     Stad…\n 8 Group…     1 Tue   2022… 22:00 Fran…   4   4–1     0.5 au A… 40,875     Al J…\n 9 Group…     1 Wed   2022… 13:00 Moro…   0.4 0–0     0.5 hr C… 59,407     Al B…\n10 Group…     1 Wed   2022… 16:00 Germ…   3.1 1–2     1.5 jp J… 42,608     Khal…\n# ℹ 57 more rows\n# ℹ 3 more variables: Referee &lt;chr&gt;, `Match Report` &lt;chr&gt;, Notes &lt;chr&gt;\n\n\n\n# Rename duplicate columns to make them unique\ncolnames &lt;- names(scores_data1) &lt;- make.unique(names(scores_data1))\n\n# Clean data\nscores_data1 &lt;- scores_data1[, 1:(ncol(scores_data1) - 2)] %&gt;% \n  select(-xG, -xG.1) %&gt;% \n  rename(week = Wk) %&gt;% \n  rename_with(~ str_to_lower(.), everything()) %&gt;% \n  slice(-c(17, 34, 51)) %&gt;% \n  mutate(away = str_remove(away, \"^[A-Za-z]+ \"),\n         home = str_remove(home, \" [A-Za-z]+$\"),\n         venue = str_remove(venue, \" \\\\(Neutral Site\\\\)\"))\n\nscores_data1\n\n# A tibble: 64 × 11\n   round       week day   date  time  home  score away  attendance venue referee\n   &lt;chr&gt;      &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  \n 1 Group sta…     1 Sun   2022… 19:00 Qatar 0–2   Ecua… 67,372     Al B… Daniel…\n 2 Group sta…     1 Mon   2022… 16:00 Engl… 6–2   IR I… 45,334     Khal… Raphae…\n 3 Group sta…     1 Mon   2022… 19:00 Sene… 0–2   Neth… 41,721     Al T… Wilton…\n 4 Group sta…     1 Mon   2022… 22:00 Unit… 1–1   Wales 43,418     Ahme… Abdulr…\n 5 Group sta…     1 Tue   2022… 13:00 Arge… 1–2   Saud… 88,012     Lusa… Slavko…\n 6 Group sta…     1 Tue   2022… 16:00 Denm… 0–0   Tuni… 42,925     Educ… César …\n 7 Group sta…     1 Tue   2022… 19:00 Mexi… 0–0   Pola… 39,369     Stad… Chris …\n 8 Group sta…     1 Tue   2022… 22:00 Fran… 4–1   Aust… 40,875     Al J… Victor…\n 9 Group sta…     1 Wed   2022… 13:00 Moro… 0–0   Croa… 59,407     Al B… Fernan…\n10 Group sta…     1 Wed   2022… 16:00 Germ… 1–2   Japan 42,608     Khal… Iván B…\n# ℹ 54 more rows"
  },
  {
    "objectID": "interactive_maps_github.html",
    "href": "interactive_maps_github.html",
    "title": "Mini Project 1B: Interactive Maps",
    "section": "",
    "text": "library(sf)\nstates &lt;- read_sf(\"https://rstudio.github.io/leaflet/json/us-states.geojson\")\nclass(states)\nstates\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\nSimple feature collection with 52 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -188.9049 ymin: 17.92956 xmax: -65.6268 ymax: 71.35163\nGeodetic CRS:  WGS 84\n# A tibble: 52 × 4\n   id    name                  density                                  geometry\n   &lt;chr&gt; &lt;chr&gt;                   &lt;dbl&gt;                        &lt;MULTIPOLYGON [°]&gt;\n 1 01    Alabama                 94.6  (((-87.3593 35.00118, -85.60667 34.98475…\n 2 02    Alaska                   1.26 (((-131.602 55.11798, -131.5692 55.28229…\n 3 04    Arizona                 57.0  (((-109.0425 37.00026, -109.048 31.33163…\n 4 05    Arkansas                56.4  (((-94.47384 36.50186, -90.15254 36.4963…\n 5 06    California             242.   (((-123.2333 42.00619, -122.3789 42.0116…\n 6 08    Colorado                49.3  (((-107.9197 41.00391, -105.729 40.99843…\n 7 09    Connecticut            739.   (((-73.05353 42.03905, -71.79931 42.0226…\n 8 10    Delaware               464.   (((-75.41409 39.80446, -75.5072 39.68396…\n 9 11    District of Columbia 10065    (((-77.03526 38.99387, -76.90929 38.8952…\n10 12    Florida                353.   (((-85.49714 30.99754, -85.00421 31.0030…\n# ℹ 42 more rows"
  },
  {
    "objectID": "interactive_maps_github.html#r-markdown",
    "href": "interactive_maps_github.html#r-markdown",
    "title": "Mini Project 1B: Interactive Maps",
    "section": "R Markdown",
    "text": "R Markdown\n\nAn Interactive Numeric Map: The Highest Violent Crime Rate Type in each State.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(leaflet)\nlibrary(shiny)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ ggplot2   3.5.1     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\ncrime &lt;- read.csv(\"https://corgis-edu.github.io/corgis/datasets/csv/state_crime/state_crime.csv\")\n\nviolent_crimes &lt;- crime\n\nstates &lt;- states %&gt;%\n   left_join(violent_crimes, \n             by = c(\"name\" = \"State\"))\n\nviolent_crimes &lt;- violent_crimes %&gt;%\n  mutate(State = tolower(State))\n\ndata_mapped &lt;- violent_crimes %&gt;%\n   left_join(states, \n             by = c(\"State\" = \"name\"))\n\nstates_map &lt;- map_data(\"state\")\n\n\n# Summarize violent crimes by type\nviolent_crimes &lt;- crime %&gt;%\n  group_by(State) %&gt;% \n  summarize(Data.Totals.Violent.Assault = sum(Data.Totals.Violent.Assault),\n            Data.Totals.Violent.Rape = sum(Data.Totals.Violent.Rape),\n            Data.Totals.Violent.Robbery = sum(Data.Totals.Violent.Robbery),\n            Data.Totals.Violent.Murder = sum(Data.Totals.Violent.Murder)) %&gt;% \n  select(State, \n          Data.Totals.Violent.Assault, \n          Data.Totals.Violent.Rape, \n          Data.Totals.Violent.Robbery, \n          Data.Totals.Violent.Murder) %&gt;%\n   mutate(Highest_Crime = pmax(Data.Totals.Violent.Assault, \n                               Data.Totals.Violent.Rape, \n                               Data.Totals.Violent.Robbery,\n                               Data.Totals.Violent.Murder, na.rm = TRUE)) %&gt;%\n   mutate(Highest_Crime_Type = case_when(\n     Highest_Crime == Data.Totals.Violent.Assault ~ \"Assault\",\n     Highest_Crime == Data.Totals.Violent.Rape ~ \"Rape\",\n     Highest_Crime == Data.Totals.Violent.Robbery ~ \"Robbery\",\n     Highest_Crime == Data.Totals.Violent.Murder ~ \"Murder\",\n     TRUE ~ NA_character_\n   )) %&gt;%\n   select(State, \n          Highest_Crime_Type)\n\n\ndata_mapped &lt;- violent_crimes %&gt;%\n   left_join(states,\n             by = c(\"State\" = \"name\"))\n \nstates &lt;- states %&gt;%\n   left_join(violent_crimes, by = c(\"name\" = \"State\"))\n\n\n# Color mapping for different crime types\nstates &lt;- states %&gt;%\n   mutate(c = case_when(\n      Highest_Crime_Type == \"Assault\" ~ \"darkred\",\n      Highest_Crime_Type == \"Rape\" ~ \"white\",\n      Highest_Crime_Type == \"Robbery\" ~ \"lightyellow\",\n      Highest_Crime_Type == \"Murder\" ~ \"white\",\n      TRUE ~ \"grey\"\n))\n \n\nviolent_crimes &lt;- violent_crimes %&gt;%\n   mutate(State = tolower(State))\n\n\n# leaflet  \nleaflet(states) %&gt;%\n   setView(lng = -96, \n           lat = 37.8, \n           zoom = 4) %&gt;% \n   addTiles() %&gt;%\n   addPolygons(\n     fillColor = states$c,\n     weight = 1,\n     opacity = 1,\n     color = \"black\",\n     dashArray = \"3\",\n     fillOpacity = 0.7,\n     highlight = highlightOptions(\n       weight = 2,\n       color = \"white\",\n       dashArray = \"\",\n       fillOpacity = 0.7,\n       bringToFront = TRUE\n     ),\n     label = paste(states$name, \":\", states$Highest_Crime_Type),\n     labelOptions = labelOptions(\n       style = list(\"font-weight\" = \"normal\", \n                    padding = \"3px 8px\"),\n       textsize = \"15px\",\n       direction = \"auto\"))\n\nWarning in sf::st_is_longlat(x): bounding box has potentially an invalid value\nrange for longlat data\n\n\n\n\n\n\nDescription: An interactive numeric map of the United States (excluding Alaska and Hawaii) which visualizes the most common violent crime by state, with different colors representing types of crimes: red for assault, blue for rape, green for robbery, purple for murder, and grey where data is unavailable. The map labels each state with the crime type it experiences most frequently. The aim is to visualize the geographical distribution of violent crimes across the country, which helps in identify regional patterns that might influence decisions on crime prevention and safety precautions."
  },
  {
    "objectID": "mini_project1B.html",
    "href": "mini_project1B.html",
    "title": "Mini Project 1A: Static Maps",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mdsr)\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(dplyr)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\n\nA Static Numeric Map: Total Violent Crime Rate by State(Excluding Alaska and Hawaii)\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(dplyr)\n\n\ncrime &lt;- read.csv(\"https://corgis-edu.github.io/corgis/datasets/csv/state_crime/state_crime.csv\")\n\n\ncrime_data &lt;- crime %&gt;%\n  select(State, Data.Rates.Violent.All)\n\n\ncrime_data &lt;- crime_data %&gt;%\n  filter(!State %in% c(\"Alaska\", \n                       \"Hawaii\"))\n\n\ncrime_data$State &lt;- tolower(crime_data$State)\n\n# US map data\nus_states &lt;- map_data(\"state\")\n\n# Merging data\nmap_data_merged &lt;- merge(us_states, \n                         crime_data, \n                         by.x = \"region\", \n                         by.y = \"State\", \n                         all.x = TRUE)\n\n# Creating the map\nggplot(map_data_merged, \n       aes(x = long, \n           y = lat, \n           group = group, \n           fill = Data.Rates.Violent.All)) +\n  geom_polygon(color = \"black\") + \n  scale_fill_continuous(name = \"Violent Crime Rate\", \n                        low = \"lightyellow\", \n                        high = \"darkred\", \n                        na.value = \"grey\") +\n  theme_minimal() +\n  labs(title = \"Total Violent Crime Rate by State (Excluding Alaska & Hawaii)\", \n       x = \"Longitude\", \n       y = \"Latitude\",\n       caption = \"Source: Corgis State Crime Dataset\") +\n  theme(plot.title = element_text(hjust = 0.5, \n                                  face = \"bold\", \n                                  size = 14),\n        plot.subtitle = element_text(hjust = 0.5, \n                                     size = 12))\n\n\n\n\n\n\n\n\nAlt-text: This is a static map that visualizes the total violent crime rate by state in the United States, excluding Alaska and Hawaii. Each state is colored according to its violent crime rate per 100,000 people, with a gradient scale transitioning from light yellow (lower crime rates) to dark red (higher crime rates). The plot is titled “Total Violent Crime Rate by State (Excluding Alaska and Hawaii),” and there is a legend on the side indicating the color scale for crime rates. An annotation at the bottom notes the data source as the CORGIS State Crime Dataset.\nThis map makes it easy to identify areas with high and low crime rates and the purpose of it is to see the regional differences in violent crime rates which can be used in discussions of public safety and law policies. States colored in darker shades of red indicate a higher rate of violent crime, leading to potentially looking into the underlying causes. Additionally, the exclusion of Alaska and Hawaii allows for a focused comparison among the contiguous states. We can see that all states are of varied shades of light yellow, which is not that helpful when it comes to figuring out the state with the highest and lowest. This could be improved by looking at violent crime rates in a specific time span.\n\nA Static Categorical Map: Most Common Violent Crime by State (Excluding Alaska & Hawaii ˆ\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(dplyr)\n\n# Load the crime dataset\ncrime &lt;- read.csv(\"https://corgis-edu.github.io/corgis/datasets/csv/state_crime/state_crime.csv\")\n\n# Exclude Alaska and Hawaii and select relevant columns\nviolent_crimes &lt;- crime %&gt;%\n  filter(!State %in% c(\"Alaska\", \"Hawaii\")) %&gt;%\n  select(State, Data.Totals.Violent.Assault, Data.Totals.Violent.Rape, \n         Data.Totals.Violent.Robbery, Data.Totals.Violent.Murder)\n\n\n# Convert state names to lowercase for joining with map data\nviolent_crimes &lt;- violent_crimes %&gt;%\n  mutate(State = tolower(State))\n\n# Find the most common violent crime type for each state\nviolent_crimes &lt;- violent_crimes %&gt;%\n  mutate(Highest_Crime_Type = case_when(\n    Data.Totals.Violent.Assault &gt;= Data.Totals.Violent.Rape & \n    Data.Totals.Violent.Assault &gt;= Data.Totals.Violent.Robbery & \n    Data.Totals.Violent.Assault &gt;= Data.Totals.Violent.Murder ~ \"Assault\",\n    \n    Data.Totals.Violent.Rape &gt;= Data.Totals.Violent.Assault & \n    Data.Totals.Violent.Rape &gt;= Data.Totals.Violent.Robbery & \n    Data.Totals.Violent.Rape &gt;= Data.Totals.Violent.Murder ~ \"Rape\",\n    \n    Data.Totals.Violent.Robbery &gt;= Data.Totals.Violent.Assault & \n    Data.Totals.Violent.Robbery &gt;= Data.Totals.Violent.Rape & \n    Data.Totals.Violent.Robbery &gt;= Data.Totals.Violent.Murder ~ \"Robbery\",\n    \n    Data.Totals.Violent.Murder &gt;= Data.Totals.Violent.Assault & \n    Data.Totals.Violent.Murder &gt;= Data.Totals.Violent.Rape & \n    Data.Totals.Violent.Murder &gt;= Data.Totals.Violent.Robbery ~ \"Murder\",\n    \n    TRUE ~ NA_character_\n  ))\n\n# Load US map data\nus_states &lt;- map_data(\"state\")\n\n# Merge map data with crime data\nmap_data_merged &lt;- merge(us_states, violent_crimes, by.x = \"region\", by.y = \"State\", all.x = TRUE)\n\n# Create a categorical static map\nggplot(map_data_merged, aes(x = long, y = lat, group = group, fill = Highest_Crime_Type)) +\n  geom_polygon(color = \"black\") + \n  scale_fill_manual(values = c(\"Assault\" = \"lightblue\", \"Rape\" = \"antiquewhite2\", \"Robbery\" = \"cornflowerblue\", \"Murder\" = \"burlywood3\"), \n                    na.value = \"grey\", name = \"Most Common Crime Type\") +\n  theme_minimal() +\n  labs(title = \"Most Common Violent Crime by State (Excluding Alaska & Hawaii)\",\n       subtitle = \"Categorical Map of the U.S. Showing the Most Prevalent Type of Violent Crime\",\n       x = \"Longitude\", \n       y = \"Latitude\",\n       caption = \"Source: Corgis State Crime Dataset\") +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n        plot.subtitle = element_text(hjust = 0.5, size = 12),\n        legend.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\nDescription: For this specific map, I intended it to be categorical but not interactive. This is an easy map to show the most common violent crime act in every state where red is assault, blue is rape and green is robbery. We can see that assault dominates most of the united states while robbery(green) dominates 7 states only. There is zero domination of rape crimes. I like this map since it’s very straight forward, I would want to add abbreviations of each state to make it easier for the viewers to detect where every crime is dominant."
  },
  {
    "objectID": "mini_project1B.html#r-markdown",
    "href": "mini_project1B.html#r-markdown",
    "title": "Mini Project 1A: Static Maps",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(mdsr)\nlibrary(maps)\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nlibrary(dplyr)\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\n\n\nA Static Numeric Map: Total Violent Crime Rate by State(Excluding Alaska and Hawaii)\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(dplyr)\n\n\ncrime &lt;- read.csv(\"https://corgis-edu.github.io/corgis/datasets/csv/state_crime/state_crime.csv\")\n\n\ncrime_data &lt;- crime %&gt;%\n  select(State, Data.Rates.Violent.All)\n\n\ncrime_data &lt;- crime_data %&gt;%\n  filter(!State %in% c(\"Alaska\", \n                       \"Hawaii\"))\n\n\ncrime_data$State &lt;- tolower(crime_data$State)\n\n# US map data\nus_states &lt;- map_data(\"state\")\n\n# Merging data\nmap_data_merged &lt;- merge(us_states, \n                         crime_data, \n                         by.x = \"region\", \n                         by.y = \"State\", \n                         all.x = TRUE)\n\n# Creating the map\nggplot(map_data_merged, \n       aes(x = long, \n           y = lat, \n           group = group, \n           fill = Data.Rates.Violent.All)) +\n  geom_polygon(color = \"black\") + \n  scale_fill_continuous(name = \"Violent Crime Rate\", \n                        low = \"lightyellow\", \n                        high = \"darkred\", \n                        na.value = \"grey\") +\n  theme_minimal() +\n  labs(title = \"Total Violent Crime Rate by State (Excluding Alaska & Hawaii)\", \n       x = \"Longitude\", \n       y = \"Latitude\",\n       caption = \"Source: Corgis State Crime Dataset\") +\n  theme(plot.title = element_text(hjust = 0.5, \n                                  face = \"bold\", \n                                  size = 14),\n        plot.subtitle = element_text(hjust = 0.5, \n                                     size = 12))\n\n\n\n\n\n\n\n\nAlt-text: This is a static map that visualizes the total violent crime rate by state in the United States, excluding Alaska and Hawaii. Each state is colored according to its violent crime rate per 100,000 people, with a gradient scale transitioning from light yellow (lower crime rates) to dark red (higher crime rates). The plot is titled “Total Violent Crime Rate by State (Excluding Alaska and Hawaii),” and there is a legend on the side indicating the color scale for crime rates. An annotation at the bottom notes the data source as the CORGIS State Crime Dataset.\nThis map makes it easy to identify areas with high and low crime rates and the purpose of it is to see the regional differences in violent crime rates which can be used in discussions of public safety and law policies. States colored in darker shades of red indicate a higher rate of violent crime, leading to potentially looking into the underlying causes. Additionally, the exclusion of Alaska and Hawaii allows for a focused comparison among the contiguous states. We can see that all states are of varied shades of light yellow, which is not that helpful when it comes to figuring out the state with the highest and lowest. This could be improved by looking at violent crime rates in a specific time span.\n\nA Static Categorical Map: Most Common Violent Crime by State (Excluding Alaska & Hawaii ˆ\n\n\n# Load necessary libraries\nlibrary(ggplot2)\nlibrary(maps)\nlibrary(dplyr)\n\n# Load the crime dataset\ncrime &lt;- read.csv(\"https://corgis-edu.github.io/corgis/datasets/csv/state_crime/state_crime.csv\")\n\n# Exclude Alaska and Hawaii and select relevant columns\nviolent_crimes &lt;- crime %&gt;%\n  filter(!State %in% c(\"Alaska\", \"Hawaii\")) %&gt;%\n  select(State, Data.Totals.Violent.Assault, Data.Totals.Violent.Rape, \n         Data.Totals.Violent.Robbery, Data.Totals.Violent.Murder)\n\n\n# Convert state names to lowercase for joining with map data\nviolent_crimes &lt;- violent_crimes %&gt;%\n  mutate(State = tolower(State))\n\n# Find the most common violent crime type for each state\nviolent_crimes &lt;- violent_crimes %&gt;%\n  mutate(Highest_Crime_Type = case_when(\n    Data.Totals.Violent.Assault &gt;= Data.Totals.Violent.Rape & \n    Data.Totals.Violent.Assault &gt;= Data.Totals.Violent.Robbery & \n    Data.Totals.Violent.Assault &gt;= Data.Totals.Violent.Murder ~ \"Assault\",\n    \n    Data.Totals.Violent.Rape &gt;= Data.Totals.Violent.Assault & \n    Data.Totals.Violent.Rape &gt;= Data.Totals.Violent.Robbery & \n    Data.Totals.Violent.Rape &gt;= Data.Totals.Violent.Murder ~ \"Rape\",\n    \n    Data.Totals.Violent.Robbery &gt;= Data.Totals.Violent.Assault & \n    Data.Totals.Violent.Robbery &gt;= Data.Totals.Violent.Rape & \n    Data.Totals.Violent.Robbery &gt;= Data.Totals.Violent.Murder ~ \"Robbery\",\n    \n    Data.Totals.Violent.Murder &gt;= Data.Totals.Violent.Assault & \n    Data.Totals.Violent.Murder &gt;= Data.Totals.Violent.Rape & \n    Data.Totals.Violent.Murder &gt;= Data.Totals.Violent.Robbery ~ \"Murder\",\n    \n    TRUE ~ NA_character_\n  ))\n\n# Load US map data\nus_states &lt;- map_data(\"state\")\n\n# Merge map data with crime data\nmap_data_merged &lt;- merge(us_states, violent_crimes, by.x = \"region\", by.y = \"State\", all.x = TRUE)\n\n# Create a categorical static map\nggplot(map_data_merged, aes(x = long, y = lat, group = group, fill = Highest_Crime_Type)) +\n  geom_polygon(color = \"black\") + \n  scale_fill_manual(values = c(\"Assault\" = \"lightblue\", \"Rape\" = \"antiquewhite2\", \"Robbery\" = \"cornflowerblue\", \"Murder\" = \"burlywood3\"), \n                    na.value = \"grey\", name = \"Most Common Crime Type\") +\n  theme_minimal() +\n  labs(title = \"Most Common Violent Crime by State (Excluding Alaska & Hawaii)\",\n       subtitle = \"Categorical Map of the U.S. Showing the Most Prevalent Type of Violent Crime\",\n       x = \"Longitude\", \n       y = \"Latitude\",\n       caption = \"Source: Corgis State Crime Dataset\") +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\", size = 14),\n        plot.subtitle = element_text(hjust = 0.5, size = 12),\n        legend.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\nDescription: For this specific map, I intended it to be categorical but not interactive. This is an easy map to show the most common violent crime act in every state where red is assault, blue is rape and green is robbery. We can see that assault dominates most of the united states while robbery(green) dominates 7 states only. There is zero domination of rape crimes. I like this map since it’s very straight forward, I would want to add abbreviations of each state to make it easier for the viewers to detect where every crime is dominant."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Rania Abdul Hafiz",
    "section": "",
    "text": "Hi there! My name is Rania Abdul Hafiz. I am a student at St. Olaf College majoring in Kinesiology and Statistics and Data Science concentration. I work as a Sports Medicine Assistant and I like to use my data science skills to explore various trends in the health field and specifically sports injuries. Poke around my website to learn more!"
  }
]